params=
    {'decoder': 
        {
            'decoder': 
                {
                    'mlp': 
                        {'ffn_layer1': 
                            {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 2048), dtype=float32), 
                                        names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 
                        'wi': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 2048), dtype=float32), 
                                        names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 
                        'wo': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(2048, 32, 512), dtype=float32), 
                                        names=('mlp', 'layers', 'embed'), mesh=None, rules=None)
                                }
                        }, 
                    'post_self_attention_layer_norm': 
                        {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32), dtype=float32), 
                                        names=('embed', 'layers'), mesh=None, rules=None)
                        }, 
                    'pre_self_attention_layer_norm': 
                        {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32), dtype=float32), 
                                        names=('embed', 'layers'), mesh=None, rules=None)
                        }, 
                    'self_attention': 
                        {'key': 
                            {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 32, 128), dtype=float32), 
                                        names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)
                            }, 
                        'out': 
                            {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(32, 32, 128, 512), dtype=float32), 
                                        names=('heads', 'layers', 'kv', 'embed'), mesh=None, rules=None)
                            }, 
                        'query': 
                            {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 32, 128), dtype=float32), 
                                        names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)
                            }, 
                        'value': 
                            {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 32, 128), dtype=float32), 
                                        names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)
                            }
                        }
                }, 
            'decoder_norm': 
                    {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512,), dtype=float32), names=('embed',), 
                        mesh=None, rules=None)
                    }
        }, 
        'token_embedder': 
                {
                    'embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(50272, 512), dtype=float32), 
                    names=('vocab', 'embed'), mesh=None, rules=None)
                }
    }, 
    
    
    
    tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7fbe54e2dbd0>, update=<function chain.<locals>.update_fn at 0x7fbe54e2de10>), opt_state=(ScaleByAdamState(count=ShapeDtypeStruct(shape=(), dtype=int32), mu={'decoder': {'decoder': {'mlp': {'ffn_layer1': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wi': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wo': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(2048, 32, 512), dtype=float32), names=('mlp', 'layers', 'embed'), mesh=None, rules=None)}}, 'post_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'pre_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'self_attention': {'key': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 32, 128), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'out': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(32, 32, 128, 512), dtype=float32), names=('heads', 'layers', 'kv', 'embed'), mesh=None, rules=None)}, 'query': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 32, 128), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'value': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 32, 128), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}}}, 'decoder_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512,), dtype=float32), names=('embed',), mesh=None, rules=None)}}, 'token_embedder': {'embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(50272, 512), dtype=float32), names=('vocab', 'embed'), mesh=None, rules=None)}}, nu={'decoder': {'decoder': {'mlp': {'ffn_layer1': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wi': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wo': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(2048, 32, 512), dtype=float32), names=('mlp', 'layers', 'embed'), mesh=None, rules=None)}}, 'post_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'pre_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'self_attention': {'key': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 32, 128), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'out': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(32, 32, 128, 512), dtype=float32), names=('heads', 'layers', 'kv', 'embed'), mesh=None, rules=None)}, 'query': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 32, 128), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'value': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 32, 32, 128), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}}}, 'decoder_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512,), dtype=float32), names=('embed',), mesh=None, rules=None)}}, 'token_embedder': {'embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(50272, 512), dtype=float32), names=('vocab', 'embed'), mesh=None, rules=None)}}), EmptyState(), ScaleByScheduleState(count=ShapeDtypeStruct(shape=(), dtype=int32))))